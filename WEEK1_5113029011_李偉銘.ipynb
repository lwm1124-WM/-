
%pip install yfinance
%pip install beautifulsoup4

import requests
import yfinance as yf
import pandas as pd
import datetime as dt
import matplotlib.pyplot as plt
from bs4 import BeautifulSoup

tickers = ["2206.TW"]  # 三陽工業
end = dt.date.today()
start = end - dt.timedelta(days=180)

multi = len(tickers) > 1
group_by = "ticker" if multi else "column"

df_yf = yf.download(
    tickers,
    start=start,
    end=end,
    group_by=group_by,
    auto_adjust=False,
    threads=True
)
df_yf = pd.DataFrame(df_yf).reset_index()

if multi:
    new_cols = []
    for c in df_yf.columns:
        if isinstance(c, tuple):
            a, b = c
            if a in ["Open","High","Low","Close","Adj Close","Volume"]:
                new_cols.append(f"{a}_{b}")
            elif b in ["Open","High","Low","Close","Adj Close","Volume"]:
                new_cols.append(f"{b}_{a}")
            else:
                new_cols.append("_".join([str(x) for x in c if x]))
        else:
            new_cols.append(c)
    df_yf.columns = new_cols

print("yfinance 前5筆：")
print(df_yf.head())

plt.figure(figsize=(12, 7))
if multi:
    for t in tickers:
        col = f"Close_{t}"
        if col in df_yf.columns:
            plt.plot(df_yf["Date"], df_yf[col], label=col)
else:
    plt.plot(df_yf["Date"], df_yf["Close"], label=f"Close_{tickers[0]}")

step = max(1, len(df_yf) // 10) if len(df_yf) else 1
plt.xticks(df_yf["Date"].iloc[::step], rotation=45)
plt.title(f"{', '.join(tickers)} 收盤價（yfinance）")
plt.xlabel("日期")
plt.ylabel("價格")
plt.legend(loc="upper left")
plt.grid(True)
plt.tight_layout()
plt.show()

# ---------------- Yahoo 股價頁解析函式（修正版） ----------------
def yahoo_stock(stock_id: str) -> pd.DataFrame:
    """
    解析 Yahoo 股價總覽區塊（qsp-overview-realtime-info）。
    傳入不含 .TW 的代號，例如 '2206'。
    回傳：單列 DataFrame（含時間與各欄位）；若抓不到欄位，會回傳空表。
    """
    url = f"https://tw.stock.yahoo.com/quote/{stock_id}.TW"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0.0.0 Safari/537.36"
    }

    try:
        resp = requests.get(url, headers=headers, timeout=20)
        resp.raise_for_status()
    except requests.RequestException as e:
        print(f"HTTP 取得失敗：{e}")
        return pd.DataFrame()

    soup = BeautifulSoup(resp.text, "html.parser")

    # 找「即時資訊」區塊
    section = soup.find("section", {"id": "qsp-overview-realtime-info"})
    if section is None:
        print("找不到 qsp-overview-realtime-info 區塊（可能頁面結構已變或需 JS）。")
        return pd.DataFrame()

    # 取時間（屬性是 datetime，不是 datatime）
    time_tag = section.find("time")
    dt_attr = time_tag.get("datetime") if time_tag else None

    # 取 UL > li > span 結構
    ul = section.find("ul")
    if ul is None:
        print("找不到即時資訊清單（ul）。")
        return pd.DataFrame()

    items = ul.find_all("li")
    fields, datas = [], []

    for li in items:
        spans = li.find_all("span")
        # 通常每個 li 會是 [欄名, 值]
        if not spans:
            continue
        # 取第一個非空文字當欄名、其後第一個非空文字當值
        name = next((s.get_text(strip=True) for s in spans if s.get_text(strip=True)), "")
        value = ""
        for s in spans[1:]:
            txt = s.get_text(strip=True)
            if txt:
                value = txt
                break
        if name and value:
            fields.append(name)
            datas.append(value)

    if not fields:
        print("未能解析出欄位資料（可能頁面改版）。")
        return pd.DataFrame()

    df = pd.DataFrame([datas], columns=fields)
    df.insert(0, "日期時間", dt_attr or "")
    df.insert(1, "股號", f"{stock_id}.TW")
    return df

# --------------- main：呼叫 Yahoo 解析 ---------------
stock_id = "2206"
df_yahoo = yahoo_stock(stock_id)
print("\nYahoo 解析結果：")
print(df_yahoo)

# --------------- 取得季報表 ---------------
url = f'https://tw.stock.yahoo.com/quote/{stock_id}/income-statement'
words = url.split('/')
print(words)

k = words[-1]
print(k)

# 函數可用於奇摩財報
def url_find(url):

    # 取得 url 的所有 route
    words = url.split('/')

    # 取得最後一個 route
    # 為了知道是損益表、資產負債表、現金流量表
    laset_word = words[-1]

    # 使用requests取得網頁內容
    response = requests.get(url)

    # 取得 HTML 文本
    html = response.content

    # 使用Beautiful Soup解析HTML內容
    soup = BeautifulSoup(html, 'html.parser')

    # 找到表格的表頭 qsp-incom-statment-table
    table_soup = soup.find('section', {'id': 'qsp-{}-table'.format(laset_word)})

    # 找到對應類別標籤
    table_fields=table_soup.find('div', class_='table-header')

    # 解析表頭內容
    table_fields_lines = list(table_fields.stripped_strings)


    # 找到對應的資料
    data_rows = table_soup.find_all('li' ,class_='List(n)')

    # 解析資料行內容
    data = []
    for row in data_rows:
        row_data = list(row.stripped_strings)
        data.append(row_data)

    # 建立 DataFrame
    df = pd.DataFrame(data, columns=table_fields_lines)
    return df

'''main'''

# 抓損益表
# url = f'https://tw.stock.yahoo.com/quote/{stock_id}/income-statement'
# 抓資產負債表
# url = f'https://tw.stock.yahoo.com/quote/{stock_id}/balance-sheet'
# 抓現金流量表
url = f'https://tw.stock.yahoo.com/quote/{stock_id}/cash-flow-statement'

# 抓取季報表資料
df = url_find(url).transpose()

# 資料處理
df.columns = df.iloc[0]
df = df[1:]
df.insert(0, '年度/季別', df.index)
df.columns.name = None
df.reset_index(drop=True, inplace=True)

# 輸出資料後5筆
print(df)